{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> SVM Model for Banco Santander </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING ALL NECESSARY LIBRARIES\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('expand_frame_repr', False)\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING THE TRAINING FILE\n",
    "\n",
    "df_train = pd.read_csv(\"C:\\\\Users\\\\sivac\\\\Documents\\\\Python Projects\\\\Banco Santander Kaggle\\\\input\\\\train.csv\")\n",
    "#df_test = pd.read_csv(\"C:\\\\Users\\\\sivac\\\\Documents\\\\Python Projects\\\\Banco Santander Kaggle\\\\input\\\\test.csv\")\n",
    "\n",
    "# PREPARING TRAIN DATA\n",
    "\n",
    "df_train.drop('ID_code', axis=1, inplace=True)\n",
    "y = df_train['target']\n",
    "x = df_train.drop('target', axis=1)\n",
    "\n",
    "#ID = df_test.ID_code\n",
    "#df_test.drop('ID_code', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN TEST SPLIT\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(x,y, stratify=y, random_state=1, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STANDARDIZING FEATURES USING STANDARD SCALER\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "colNames = x_train.columns\n",
    "\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_train = pd.DataFrame(data=x_train, columns=colNames)\n",
    "\n",
    "x_validation = scaler.fit_transform(x_validation)\n",
    "x_validation = pd.DataFrame(data=x_validation, columns=colNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNDER SAMPLING DATA\n",
    "sampleData = x_train.copy()\n",
    "sampleData['target'] = y_train\n",
    "\n",
    "underSample_length = len(sampleData[sampleData.target == 1])\n",
    "\n",
    "zero_target_indices = sampleData[sampleData.target == 0].index\n",
    "random_indices = np.random.choice(zero_target_indices, underSample_length, replace=False)\n",
    "\n",
    "target_data = sampleData[sampleData.target == 1]\n",
    "zero_target_data = sampleData[sampleData.index.isin(random_indices)]\n",
    "x_train = pd.concat([target_data, zero_target_data])\n",
    "\n",
    "y_train = x_train['target']\n",
    "x_train = x_train.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running a Support Vector Machine\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Training the model using the training data\n",
    "model = SVC(kernel='linear')\n",
    "model.fit(x_train, y_train)\n",
    "train_predictions = model.predict(x_train)\n",
    "predictions = model.predict(x_validation)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Confusion Matrix Comparison\n",
    "print(\"Confustion Matrix for Training Data - Support Vector Machine\")\n",
    "print(confusion_matrix(y_train, train_predictions))\n",
    "print(\"Confustion Matrix for Test Data - Support Vector Machine\")\n",
    "print(confusion_matrix(y_validation, predictions))\n",
    "\n",
    "# Classification Report Comparison\n",
    "print(\"Classification Report for Training Data - Support Vector Machine\")\n",
    "print(classification_report(y_train, train_predictions))\n",
    "print(\"Classification Report for Test Data - Support Vector Machine\")\n",
    "print(classification_report(y_validation, predictions))\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "predictions = model.predict_proba(x_validation)[:,1]\n",
    "roc_auc_score(y_validation, predictions, average='weighted')\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_validation, predictions)\n",
    "\n",
    "# Calculating the AUC Score\n",
    "auc = np.trapz(tpr,fpr)\n",
    "pltTitle = print(\"AUROC Plot from Decision Tree:\", \"%.4f\" %auc)\n",
    "\n",
    "# Plotting the ROC Curve\n",
    "plt.plot(fpr,tpr)\n",
    "plt.title(pltTitle)\n",
    "plt.show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
